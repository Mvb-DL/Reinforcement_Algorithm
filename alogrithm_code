import random
import collections
import datetime
import glob
import numpy as np
import pathlib
!pip install pandas
import pandas as pd
!pip install pretty_midi
import pretty_midi
!pip install tensorflow
import tensorflow as tf
from IPython import display
from typing import Dict, List, Optional, Sequence, Tuple
import os
from datetime import datetime
from packaging import version

data_dir = pathlib.PureWindowsPath('filepath')

filenames = glob.glob(str(data_dir/'**/*.mid*'))
sample_file = filenames[0]
pm = pretty_midi.PrettyMIDI(sample_file)
instrument = pm.instruments[0]
instrument_name = pretty_midi.program_to_instrument_name(instrument.program)

notelist = []

for i, note in enumerate(instrument.notes[:(len(instrument.notes)-1)]): 
    
  note_name = pretty_midi.note_number_to_name(note.pitch)  
  note = int(note.pitch)
  notelist.append(note)
    
notelist = np.array(notelist)
    
def add_arrays(listtype, arraytype, number):
                
    index = 0
    while index != number:
        listtype.append(arraytype)
        index+=1

notelist = []
listindex = 0
q_matrizen = []
reward = 0
reward_list = []

for note in notelist:
    
    note = notelist[listindex]
        
    arrlist = []
    arr = np.array(range(128))
    i = 0
    
    while i < len(arr):
        
        arrlist.append(arr)
        i+=1
        
    x = range(len(arrlist[0]))
    
    new_arr = np.array_split(x,4)
    
    length_arr = len(new_arr)
    
    length_list = list(range(length_arr))
        
    for y in length_list:
        if note in new_arr[y]:
            new_arry = new_arr[y]
            
            goal_index = np.searchsorted(new_arry, note)     
            left_from_goal_index = goal_index-1
            right_from_goal_index = goal_index+1
    
            newest_arr = np.array_split(new_arry,len(new_arry)) 
             
            newest_arr = np.array(newest_arr)
                     
            reshaped = np.reshape(new_arry, (-1, 1))
            
            new_goal_index = np.append(reshaped[goal_index], 0)
            new_goal_index = [0,0]
            
            if note == new_arr[y][0]:            
                new_left_from_goal_index = [0,0]           
            else:
                new_left_from_goal_index = np.append(reshaped[left_from_goal_index], 0)
                new_left_from_goal_index = [0,100]
            
            if note == new_arr[y][-1]:
                 new_left_from_goal_index = [0,0]   
            else:
                new_right_from_goal_index = np.append(reshaped[right_from_goal_index], 0)
                new_right_from_goal_index = [100,0]
                              
            new_env = []
            rest_index = [0,0]
            number = 29
            
            add_arrays(new_env, rest_index, number)
                          
            new_env.insert(left_from_goal_index,new_left_from_goal_index)
            new_env.insert(goal_index, new_goal_index)
            new_env.insert(right_from_goal_index,new_right_from_goal_index)
                           
            min_index = [-100,0]
            new_env.insert(0,min_index)     
            max_index = [0,-100]
            new_env.insert(len(new_env),max_index)   
            added_max_index = [0, None]
            new_env.append(added_max_index)
            added_min_index = [None, 0]
            new_env.insert(0,added_min_index)
                                   
            environment_matrix = new_env
            
            if goal_index >= 33:
                goal_index = goal_index -2
            else:
                goal_index = goal_index + 2
                      
            q_matrix = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]
           
            win_loss_states = [0, goal_index, -1]
            
            def getAllPossibleNextAction(cur_pos):
                step_matrix = [x != None for x in environment_matrix[cur_pos]]
                action = []
                if(step_matrix[0]):
                    action.append(0)    
                if(step_matrix[1]):
                    action.append(1)
                return(action)
            def isGoalStateReached(cur_pos):
                return (cur_pos in [goal_index])
            def getNextState(cur_pos, action):
                if (action == 0):
                    return cur_pos - 1
                else:
                    return cur_pos + 1
            def isGameOver(cur_pos):
                return cur_pos in win_loss_states
                   
            discount = 0.9
            learning_rate = 0.1
            for _ in range(100):
                
                cur_pos = random.choice([2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33])
                
                while(not isGameOver(cur_pos)):
                    
                    possible_actions = getAllPossibleNextAction(cur_pos)
                   
                    action = random.choice(possible_actions)
                    
                    next_state = getNextState(cur_pos, action)
                    
                    q_matrix[cur_pos][action] = q_matrix[cur_pos][action] + learning_rate * (environment_matrix[cur_pos][action] + 
                        discount * max(q_matrix[next_state]) - q_matrix[cur_pos][action])
                   
                    cur_pos = next_state
                    
            del q_matrix[0]
            del q_matrix[1]
            del q_matrix[-1]
            del q_matrix[-2]
            
            q_matrix.reverse()
            
            new_q_matrix = []     
            add_index = [-100,-100]
            new_number = 96
                
            add_arrays(new_q_matrix, add_index, number)
            
            if y == 0:
                
                for q in q_matrix:
                
                    new_q_matrix.insert(0, q)
            
            elif y == 1:
                
                for q in q_matrix:
                
                    new_q_matrix.insert(32, q)
            
            elif y == 2:
                
                for q in q_matrix:
                
                    new_q_matrix.insert(64, q)
                
            else:
                
                for q in q_matrix:
                
                    new_q_matrix.insert(96, q)
                            
            q_matrizen.append(new_q_matrix)
                        

environment_matrix = q_matrizen[0]

part_whole_environment = []
whole_environment = []
env_add_index = [0,0]
env_new_index = 0
whole_index = 0
            
while env_new_index != 128:           
        part_whole_environment.append(env_add_index)
        env_new_index+=1
        
while whole_index < len(notelist):      
    whole_environment.append(part_whole_environment)
    whole_index += 1

q_matrix = whole_environment[0]

print(environment_matrix)
print(q_matrix)
